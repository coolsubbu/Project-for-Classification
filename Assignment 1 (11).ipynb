{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import psutil\n",
    "import re\n",
    "from multiprocessing import Process\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from subprocess import call\n",
    "from numpy.random import seed\n",
    "import sys\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2 as chi_2\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier as tratc\n",
    "from sklearn.ensemble import GradientBoostingClassifier as gbc\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn import tree\n",
    "from numpy import random\n",
    "from multiprocessing import Process , Manager\n",
    "import copy\n",
    "from copy import deepcopy as cdc\n",
    "import pandas as pd\n",
    "import datetime \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import psutil\n",
    "from datetime import datetime  as dt\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"white\",color_codes=True)\n",
    "\n",
    "sys.setrecursionlimit(1000000)\n",
    "seed(42)\n",
    "random.seed(42)\n",
    "os.environ['PYTHONHASHSEED']='0'  \n",
    "try :\n",
    "        os.environ['OPENBLAS_NUM_THREADS']=\"1\"\n",
    "        import numpy\n",
    "finally:\n",
    "       if 'OPENBLAS_NUM_THREADS' in os.environ:\n",
    "              del os.environ['OPENBLAS_NUM_THREADS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_stamp():\n",
    "     print(time.strftime(\"%Y-%m-%d-%H-%M\",time.gmtime()))\n",
    "    \n",
    "def preprocessing():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "class Assignment:\n",
    "\n",
    "    \n",
    "  def __init__(self,config_file_url):\n",
    "    \n",
    "    print('initialisation stage ')\n",
    "    print(\" data loading and sanity checks \")\n",
    "    self.config_file_handle=open(config_file_url,\"r\",encoding='utf-8')\n",
    "    print(config_file_url)\n",
    "    \n",
    "    assert self.config_file_handle, ' Could not open config File'\n",
    "    \n",
    "    self.config= json.load(self.config_file_handle)\n",
    " \n",
    "    print('loading input dataset')\n",
    "    \n",
    "    self.input_data=pd.read_csv(self.config[\"DataURL\"],keep_default_na=False,encoding='latin-1')  \n",
    "    \n",
    "    \n",
    "    self.feature_data=self.input_data\n",
    "    \n",
    "    assert not self.input_data.empty, \"Could not read input dataset/ input_data empty\"\n",
    "    \n",
    "  def input_head(self):\n",
    "    \n",
    "       print(self.input_data[0:10])   \n",
    "       print(self.input_data.shape)\n",
    " \n",
    "    \n",
    "  def input_distribution(self):  \n",
    "      print('input data distribution')  \n",
    "      for w in self.input_data:  \n",
    "            print(\"\\n\\n\")\n",
    "            print(self.input_data[w].value_counts())\n",
    "            \n",
    "  def feature_distribution(self):\n",
    "      print('target variable:approved')\n",
    "      print('feature distribution with respect to Target variable: Approved')\n",
    "      \n",
    "      print(self.input_data['approved'].value_counts())\n",
    "      \n",
    "      print('Chi2 test on Target and Feature Distribution')\n",
    "      Chi2_dict={}\n",
    "      Chi2_list=[]\n",
    "      for w in self.input_data:\n",
    "        print(\"\\n\\n\")\n",
    "        print(\" FEATURE :\" + str(w))\n",
    "        print(pd.crosstab(self.input_data[w],self.input_data.approved)) \n",
    "        \n",
    "        stat,p,dof,expected=chi2_contingency(pd.crosstab(self.input_data[w],self.input_data.approved))\n",
    "        \n",
    "        prob = 0.95\n",
    "        critical = chi_2.ppf(prob, dof)\n",
    "        \n",
    "        print('Chi2 test on Target and Feature Distribution')\n",
    "      \n",
    "        print('From chi2 Statistic probability=%.3f, critical=%.5f, stat=%.5f' % (prob, critical, stat))\n",
    "        \n",
    "        if abs(stat) >= critical:\n",
    "            print('Dependent (reject H0)')\n",
    "        else:\n",
    "            print('Independent (fail to reject H0) ')\n",
    "        \n",
    "        # interpret p-value\n",
    "        alpha = 1.0 - prob\n",
    "        print('From Test significance=%.5f, p=%.5f' % (alpha, p))\n",
    "        \n",
    "        if p <= alpha:\n",
    "            print('Dependent (reject H0)')\n",
    "        else:\n",
    "            print('Independent (fail to reject H0)')\n",
    "\n",
    "        #self.input_data.plot(kind='scatter',y='',x='approved')\n",
    "  \n",
    "  def feature_engineering(self):\n",
    "      listw=[]\n",
    "      print(' Feature Engineering ')\n",
    "        \n",
    "      self.input_data['age']=None\n",
    "      self.input_data['state']=None\n",
    "      self.input_data['mail_accnt']=None\n",
    "      self.input_data['house_type']=None\n",
    "    \n",
    "      for i,w in self.input_data.iterrows():\n",
    "        \n",
    "        w['age']=-1\n",
    "        dateformat='%Y-%m-%d'\n",
    "        dt1=time.strftime(dateformat,time.gmtime())    \n",
    "        dt2=w['date_of_birth']\n",
    "        dat1=datetime.datetime.strptime(dt1,dateformat)-datetime.datetime.strptime(dt2,dateformat)        \n",
    "        w['age']=dat1.days    \n",
    "        \n",
    "        g= re.search(r'(\\w\\w)\\s+\\d{5}\\s*$',w['address'])\n",
    "                                                    \n",
    "        if g:\n",
    "            w['state']=list(g.groups('\\1'))[0]\n",
    "        else:\n",
    "            w['state']=None\n",
    "        \n",
    "        mail=re.search(r'\\w+@(\\w+\\.\\w+)\\s*',w['email'])\n",
    "        \n",
    "        if mail:\n",
    "            w['mail_accnt']=list(mail.groups('\\1'))[0]\n",
    "        else:\n",
    "            w['mail_accnt']=None\n",
    "        \n",
    "        apt=re.search(r'Apt',w['address'])\n",
    "\n",
    "        suite=re.search(r'Suite',w['address'])\n",
    "         \n",
    "        if apt:\n",
    "            w['house_type']='Apt'\n",
    "                \n",
    "        elif suite:\n",
    "            w['house_type']='Studio'\n",
    "        else:\n",
    "            w['house_type']='others'\n",
    "            \n",
    "        listw.append(w)\n",
    "      \n",
    "      Feature_Engineered_Data=pd.DataFrame(listw,columns=listw[0].keys())\n",
    "      \n",
    "      self.input_data=Feature_Engineered_Data\n",
    "      \n",
    "      #self.input_data.to_csv('')\n",
    "        \n",
    "  # Pruning the High Cardinality Categorical Features  \n",
    "  def feature_pruning(self):\n",
    "    \n",
    "    for w in self.input_data:\n",
    "      \n",
    "      if(self.input_data[w].dtype==object):  \n",
    "        wc= self.input_data[w].value_counts()\n",
    "        if len(wc)>4000:\n",
    "            \n",
    "            print('number of unique values in a categorical Data Column'+str(w)+ ' is '+str(len(wc))+' and it is high so pruning it')\n",
    "            self.feature_data.drop([w],axis=1)\n",
    "    \n",
    "    print(self.feature_data[0:10])              \n",
    "  \n",
    "  # Finding the top AUC_PR from Grid Search Models\n",
    "  def updating_o(self,model_perf,model_perf_):\n",
    "  \n",
    "   if 'AUC_PR' in model_perf_:\n",
    "    o_auc_pr=model_perf_['AUC_PR']\n",
    "    auc_pr=model_perf['AUC_PR']\n",
    "    o_tp=model_perf['TP']\n",
    "    tp=model_perf_['TP']\n",
    "\n",
    "    if(  auc_pr > o_auc_pr ):\n",
    "\n",
    "      for ky in model_perf.keys():\n",
    "\n",
    "        model_perf_[ky]=model_perf[ky]\n",
    "\n",
    "   if 'AUC_PR' not in model_perf_:\n",
    "\n",
    "      for ky in model_perf.keys():\n",
    "\n",
    "        model_perf_[ky]=model_perf[ky]\n",
    "        \"\"\"cdc( model_perf)\n",
    "        \"\"\"\n",
    "   return model_perf_\n",
    "  \n",
    "  # ML modelling using grid search   \n",
    "  def modelling(self,model,targt,targt2,prdictors,train, test ,model_typ,model_perf_list,model_perf_,model_props,ind=1,o_=0,idnt=''):\n",
    "    '''print('hi')\n",
    "    '''\n",
    "    target=targt\n",
    "    target2=targt2\n",
    "    predictors=prdictors\n",
    "\n",
    "    train=train\n",
    "    test=test\n",
    "\n",
    "    model.fit(train[predictors],train[target])\n",
    "\n",
    "    model_predictions=model.predict(test[predictors])\n",
    "\n",
    "    model_proba=model.predict_proba(test[predictors])\n",
    "\n",
    "    test['predictions']=model_predictions\n",
    "\n",
    "    test['probability']=model_proba[:,1]\n",
    "\n",
    "    pcsv=test\n",
    "    \n",
    "    # Output the Predicted Probability if required \n",
    "    \n",
    "    if(o_==1):\n",
    "        pcsv['Probability_/|\\\\']=model_proba[:,1]\n",
    "        pcsv['Predictions']=model_predictions\n",
    "        pcsv.to_csv(r'Predictions'+idnt+'  ' +str( rand )+'.csv')\n",
    " \n",
    "    tn,fp,fn,tp=confusion_matrix(test[target],model_predictions).ravel()\n",
    " \n",
    "    prcision=tp/(1+tp+fp)\n",
    "    rcall=tp/(tp+fn+1)\n",
    "    f1=2*prcision*rcall/(prcision+rcall)\n",
    "    auc_roc = metrics.roc_auc_score ( test [ target2 ] , model_proba[:,1] )\n",
    "    auc_pr = metrics.average_precision_score ( test [ target2 ] , model_proba[:,1] )\n",
    "\n",
    "\n",
    "    lng=len(pcsv)\n",
    "    pcsv_Y=pcsv[ pcsv[ target2 ] ==1 ]\n",
    "    pcsv_N=pcsv[ pcsv[ target2 ] ==0 ]\n",
    "\n",
    "    model_perf={}\n",
    "    model_perf['MODEL']=str(model_props)\n",
    "    model_perf['TP']=tp\n",
    "    model_perf['FP']=fp\n",
    "    model_perf['TN']=tn\n",
    "    model_perf['FN']=fn\n",
    "    model_perf['PRECISION']=prcision\n",
    "    model_perf['RECALL']=rcall\n",
    "    model_perf['F1']=f1\n",
    "    model_perf['AUC_ROC']=auc_roc\n",
    "    model_perf['BER (balanced Error Rate)']=1-auc_roc\n",
    "    model_perf['AUC_PR']=auc_pr\n",
    "    model_perf['AVG Probability of Y']= str(sum(pcsv_Y['probability'])/len(pcsv_Y))\n",
    "    model_perf['AVG Probability of N']=str(sum(pcsv_N['probability'])/len(pcsv_N))\n",
    "    model_perf['Min Probability of Y']=str(min(pcsv_Y['probability']))\n",
    "    model_perf['Max Probability of Y']=str(max(pcsv_Y['probability']))\n",
    "    model_perf['Fcontrib']=''\n",
    "\n",
    "    if(model_typ=='LR'):\n",
    "\n",
    "       model_perf['Fcontrib']=str([ (predictors[i],model.coef_[0][i]) for i in range( len( predictors))]) + ' intercept: ' + str( model.intercept_)\n",
    "\n",
    "    if(model_typ=='RF' or model_typ=='GBM'):\n",
    "\n",
    "       model_perf['Fcontrib']=str( [ ( predictors[i],model.feature_importances_[i] )  for i in range( len( predictors ) ) ] )\n",
    "\n",
    "    self.updating_o(model_perf,model_perf_)\n",
    "\n",
    "    \n",
    "    if(ind%10==0):\n",
    "        \n",
    "       print('currnt:'+'\\n\\n')\n",
    "       self.printMtrics(model_perf)\n",
    "\n",
    "       print(' top model '+'\\n\\n')\n",
    "       self.printMtrics(model_perf_)\n",
    "\n",
    "    pcsv={}\n",
    "    train={}\n",
    "    test={}\n",
    "    pcsv_Y={}\n",
    "    pcsv_N={}\n",
    "\n",
    "    return auc_pr , model_perf\n",
    "\n",
    "  # printing the metrics while on grid search \n",
    "  def printMtrics ( self,model_perf):\n",
    "\n",
    "     model_props=model_perf['MODEL']\n",
    "     o_tp=model_perf['TP']\n",
    "     o_p_f=model_perf['FP']\n",
    "     o_f_n=model_perf['FN']\n",
    "     o_tn=model_perf['TN']\n",
    "     o_prcision=model_perf['PRECISION']\n",
    "     o_rcall = model_perf['RECALL']\n",
    "     o_f1=model_perf['F1']\n",
    "     o_auc_roc=model_perf['AUC_ROC']\n",
    "     o_auc_pr=model_perf['AUC_PR']\n",
    "     o_ber=model_perf['BER (balanced Error Rate)']\n",
    "     o_Fcontrib=model_perf['Fcontrib']\n",
    "     avg_Probability_F=model_perf['AVG Probability of Y']\n",
    "     avg_Probability_N=model_perf['AVG Probability of N']\n",
    "     min_Probability_F=model_perf['Min Probability of Y']\n",
    "     max_Probability_F=model_perf['Max Probability of Y']\n",
    "\n",
    "     print(' MODEL ' + str(model_props))\n",
    "     print(' TP '+str(o_tp))\n",
    "     print(' FP '+str(o_p_f))\n",
    "     print(' FN '+str(o_f_n))\n",
    "     print(' TN '+str(o_tn))\n",
    "     print(' PRECISION ' +str(o_prcision))\n",
    "     print(' RECALL '+str(o_rcall))\n",
    "     print(' F1 '+str(o_f1))\n",
    "     print(' auc roc ' + str(o_auc_roc))\n",
    "     print(' auc pr '  + str(o_auc_pr))\n",
    "     print(' Balanced Error Rate ' + str( 1 - o_auc_roc))\n",
    "     \n",
    "     print(' Features and contributions :' + str(o_Fcontrib))\n",
    "\n",
    "     print('Avg Probability of Y : ' + str(avg_Probability_F))\n",
    "\n",
    "     print('Avg Probability of N : ' + str(avg_Probability_N))\n",
    "\n",
    "     print('Min Probability of Y : ' + str(min_Probability_F))\n",
    "\n",
    "     print('Top Probability of Y : ' + str(max_Probability_F))\n",
    "\n",
    "  #DECISION TREE GRID SEARCH\n",
    "\n",
    "  def dtc(self,part_id):\n",
    "\n",
    "    model_perf_list=[]\n",
    "    model_perf_dict={}\n",
    "    model_perf={}\n",
    "    model_perf_={}\n",
    "\n",
    "    cnt_model=0\n",
    "    was=dt.now()\n",
    "\n",
    "    j_=0\n",
    "\n",
    "    pr=[]\n",
    "    l1=0\n",
    "    ind=0\n",
    "    mkdepth_l= [16,14,12,10,9,7,6,4]\n",
    "    minsamplesplit_l=[4,5,6,7,9,10,14,16]\n",
    "    makftr_l=[0.2,0.5,0.7,'log2','auto','sqrt']\n",
    "    minsamplelf_l=[4,5,6,8]\n",
    "    minImpdcr_l=[0.01,0.001,0.02,0.002,0.005,0.05]\n",
    "    criteria_l=['gini','entropy']\n",
    "\n",
    "    num_iters=len(mkdepth_l)*len(minsamplesplit_l)*len(makftr_l)*len(minsamplelf_l) * len(minImpdcr_l) * len(criteria_l)\n",
    "\n",
    "    i_=0\n",
    "    for makdepth in mkdepth_l:\n",
    "       for minsamplesplit in minsamplesplit_l:\n",
    "         for makftr in makftr_l:\n",
    "            for minsamplelf in minsamplelf_l:\n",
    "              for criteria in criteria_l:\n",
    "                for minImpdcr in minImpdcr_l:\n",
    "\n",
    "                 st= int(num_iters /(psutil.cpu_count()-2)) * part_id\n",
    "                 lst=int(num_iters /(psutil.cpu_count()-2)) * ( part_id+1 )\n",
    "\n",
    "                 if i_>=st and i_ <lst:\n",
    "\n",
    "                  cnt_model=cnt_model+1\n",
    "                  last_ = was\n",
    "                  was = dt.now()\n",
    "\n",
    "                  ind=ind+1\n",
    "\n",
    "                  print ( str(i_) + ' / '+str(num_iters)+  ' duration for modelling : '+str(was-last_)+ ' till is : '+str(dt.now()-start)+ '  DT :' + ' minsamplelf  '+str(minsamplelf)+ ' maksFitursslction : '\n",
    "                         +str(makftr) + ' maksDpth : ' +str(makdepth) + ' minsamplesplit : ' + str(minsamplesplit) + 'min Impurity dcrs' +str(minImpdcr))\n",
    "\n",
    "                  model_props={}\n",
    "                  model_props['algo']='DT'\n",
    "                  model_props['Maks Fiturs']=makftr\n",
    "                  model_props['criteria']=criteria\n",
    "                  model_props['Min Sample leaf']=minsamplelf\n",
    "                  model_props['Maks depth']=makdepth\n",
    "                  model_props['Min sampleing split']=minsamplesplit\n",
    "                  model_props['class weight']='balanced'\n",
    "                  model_props['Min Impurity decrease ']=minImpdcr\n",
    "\n",
    "                  dtr_wt=DTC( max_depth=makdepth,min_samples_split=minsamplesplit,criterion=criteria ,max_features=makftr, class_weight='balanced', min_samples_leaf=minsamplelf , min_impurity_decrease=minImpdcr)\n",
    "\n",
    "                  model_props1={}\n",
    "                  model_props1['algo']='DT'\n",
    "                  model_props1['Maks Fiturs']=makftr\n",
    "                  model_props1['criteria']=criteria\n",
    "                  model_props1['Min Sample leaf']=minsamplelf\n",
    "                  model_props1['Maks depth']=makdepth\n",
    "                  model_props1['Min sampleing split']=minsamplesplit\n",
    "                  model_props1['class weight']='None'\n",
    "                  model_props1[' Min Impurity decrease ']=minImpdcr\n",
    "\n",
    "                  dtr = DTC( max_depth=makdepth,min_samples_split=minsamplesplit,criterion=criteria, max_features=makftr, min_samples_leaf=minsamplelf , min_impurity_decrease=minImpdcr)\n",
    "\n",
    "                  auc_pr,model_perf  =self.modelling(dtr_wt,target,target2,predictors,train,test,'DT',model_perf_list,model_perf_,model_props,ind)\n",
    "\n",
    "                  ind=ind+1\n",
    "\n",
    "                  auc_pr,model_perf_n  =self.modelling(dtr,target,target2,predictors,train,test,'DT',model_perf_list,model_perf_,model_props1,ind)\n",
    "\n",
    "                  model_perf_list.append(model_perf)\n",
    "\n",
    "                  model_perf_list.append(model_perf_n)\n",
    "\n",
    "                 i_=i_+1\n",
    "\n",
    "                 if(i_%1000==0):\n",
    "                               \n",
    "                     model_perf_ranking=pd.DataFrame(model_perf_list,columns=model_perf.keys())\n",
    "                     model_perf_ranking.to_csv(r'model_accuracy_dt_'+'part_'+str(part_id)+'_'+str( rand ) +' .csv')\n",
    "                     model_perf_ranking={}\n",
    "           \n",
    "    model_perf_ranking=pd.DataFrame(model_perf_list,columns=model_perf.keys())\n",
    "    model_perf_ranking.to_csv(r'model_accuracy_dt_'+'part_'+str(part_id)+'_'+str( rand ) +' .csv')\n",
    "\n",
    "    model_perf_ranking={}\n",
    "    \n",
    "  # GRID SEARCH ON RANDOM FOREST\n",
    "  def rf(self,part_id):\n",
    "    \n",
    "    njobs=psutil.cpu_count()-1\n",
    "    \n",
    "    model_perf_list =[]\n",
    "    model_perf ={}\n",
    "    model_perf_={}\n",
    "\n",
    "    cnt_model=0\n",
    "    was=dt.now()\n",
    "    j_=0\n",
    "    ind=0\n",
    "\n",
    "    makdepth_l=[16,12,8,4]\n",
    "    makftr_l=[0.2,0.5,'log2','sqrt','auto']\n",
    "    makiter_l=[500,700,1200]\n",
    "    minsamplesplit_l=[5,9,14,16]\n",
    "    minsamplelf_l=[4,6,7]\n",
    "    minImpdcr_l=[ 0.01, 0.001,0.02,0.002,0.05,0.005]\n",
    "\n",
    "    criteria_l=['gini','entropy']\n",
    "    i_=0\n",
    "\n",
    "    num_iters=len(makdepth_l)*len(makftr_l) * len(makiter_l) * len(minsamplesplit_l)  * len(minsamplelf_l) * len(criteria_l)\n",
    "\n",
    "    print( ' RF iters ' +str(num_iters))\n",
    "\n",
    "    for makdepth in makdepth_l:\n",
    "      for makftr in makftr_l:\n",
    "        for makiter in makiter_l:\n",
    "          for minsamplesplit in minsamplesplit_l:\n",
    "            for minsamplelf in minsamplelf_l:\n",
    "              for criteria in criteria_l:\n",
    "                  st=int(num_iters/(psutil.cpu_count()-2 ))*part_id\n",
    "                  last=int(num_iters/(psutil.cpu_count()-2))*(1+part_id)\n",
    "                  \"\"\"print('st:'+str(st)+ 'lst:' +str(last))\n",
    "                  \"\"\"\n",
    "\n",
    "                  if((i_ >=  int( num_iters /(psutil.cpu_count()-2)) * part_id ) and ( i_ < int(num_iters/(psutil.cpu_count()-2)) *(1+part_id) ) ):\n",
    "\n",
    "                      print('st:'+str(st)+ ' lst:' + str(last) + 'part :' +str(part_id))\n",
    "\n",
    "                      last_=was\n",
    "                      was=dt.now()\n",
    "                      ind=ind+1\n",
    "\n",
    "                      print( str(cnt_model) + '/'+ str(num_iters)+ '  ' + 'duration for modelling: '+ str( was-last_ ) + 'till is '+str(dt.now()-start)+' RF :' + ' makftr : ' +str(makftr) + ' makiter : ' +str(makiter) + ' minsamplesplit : ' +str(minsamplesplit) + '  makdepth : ' +str(makdepth) + ' minsamplelf :' +str(minsamplelf))\n",
    "\n",
    "                      cnt_model=cnt_model+1\n",
    "\n",
    "                      model_props={}\n",
    "                      model_props['algo']='RF'\n",
    "                      model_props['Maks Fiturs']=makftr\n",
    "                      model_props['Maks depth']=makdepth\n",
    "                      model_props['Min Sampling split']=minsamplesplit\n",
    "                      model_props['Min Sampling leaf']=minsamplelf\n",
    "                      model_props['Criteria']=criteria\n",
    "\n",
    "                      rft=rfc( max_depth=makdepth ,  n_jobs=njobs , min_samples_leaf=minsamplelf, max_features=makftr, n_estimators=makiter, criterion=criteria, class_weight='balanced')\n",
    "\n",
    "                      auc_pr,model_perf=self.modelling(rft , target, target2, predictors, train ,   test, 'RF' , model_perf_list , model_perf_ , model_props, ind)\n",
    "\n",
    "                      model_perf_list.append(model_perf)\n",
    "\n",
    "                  i_ = i_ +1\n",
    "\n",
    "                  if(i_%1000==0):\n",
    "                               \n",
    "                     model_perf_ranking=pd.DataFrame(model_perf_list,columns=model_perf.keys())\n",
    "                     model_perf_ranking.to_csv(r'model_accuracy_rf_'+'part_'+str(part_id)+'_'+str( rand ) +' .csv')\n",
    "                     model_perf_ranking={}\n",
    "           \n",
    "\n",
    "    model_perf_ranking=pd.DataFrame(model_perf_list,columns=model_perf.keys())\n",
    "\n",
    "    model_perf_ranking.to_csv(r'model_accuracy_rf_'+'part_'+str(part_id)+'_'+str( rand )+' .csv')\n",
    "\n",
    "    model_perf_ranking={}\n",
    "\n",
    "  #GRID SEARCH On GBM\n",
    "\n",
    "  def gbm(self,part_id):\n",
    "\n",
    "    njobs=psutil.cpu_count()-1\n",
    "\n",
    "    model_perf_list =[]\n",
    "    model_perf = {}\n",
    "    model_perf_  = {}\n",
    "\n",
    "    j_=0\n",
    "    i_=0\n",
    "\n",
    "    cnt_model=0\n",
    "    was=dt.now()\n",
    "    ind=0\n",
    "    makdepth_l= [16,12,8,4]\n",
    "    los_l= ['deviance','exponential']\n",
    "    subsample_l=[0.1,0.4,0.9]\n",
    "    makftr_l=[0.2,0.5,'log2','sqrt','auto']\n",
    "    makiter_l=[100,500,700,1000,1200]\n",
    "    lurningrayt_l=[0.1,0.001,0.01,0.2,0.002,0.02,0.06,0.05,0.005]\n",
    "    minsamplesplit_l=[4,6,8,10,16]\n",
    "\n",
    "    num_iters=len(makdepth_l) * len(los_l) * len(subsample_l) * len(makftr_l) * len(makiter_l) * len(lurningrayt_l) * len( minsamplesplit_l)\n",
    "\n",
    "    for makdepth in makdepth_l:\n",
    "      for los in los_l:\n",
    "        for subsample in  subsample_l:\n",
    "          for makftr in makftr_l:\n",
    "            for makiter in makiter_l:\n",
    "              for lurningrayt in lurningrayt_l:\n",
    "                for minsamplesplit in minsamplesplit_l:\n",
    "\n",
    "                 st= num_iters/(psutil.cpu_count()-2)*part_id\n",
    "                 lst=(num_iters/(psutil.cpu_count()-2))*(1+part_id)\n",
    "\n",
    "                 if ( ( i_ >= st ) and ( i_ < lst ) ) :\n",
    "                  print('st :' +str(st) + ' lst :' + str(lst) )\n",
    "                  cnt_model=cnt_model+1\n",
    "                  last_=was\n",
    "                  was=dt.now()\n",
    "\n",
    "                  ind=ind+1\n",
    "\n",
    "                  print(str(cnt_model) + ' / '+  str(num_iters)  +' duration of modelling : ' + str(was-last_) + ' till is : '+str(dt.now()-start)+ '  GBM :' + ' loss: ' +str(los) + ' Subsample :'+str(subsample) + ' maksFiturslction : ' +str(makftr) + ' makiter: '+ str(makiter) + ' lurningrayt : ' + str(lurningrayt) + ' maksDpth : ' + str(makdepth) + ' minsamplesplit : ' + str(minsamplesplit))\n",
    "\n",
    "                 model_props={}\n",
    "                 model_props['algo']='GBM'\n",
    "                 model_props['loss']=los\n",
    "                 model_props['Subsampleing']=subsample\n",
    "                 model_props['NumTrs']=makiter\n",
    "                 model_props['Maks Fiturs']=makftr\n",
    "                 model_props['Learning rate']=lurningrayt\n",
    "                 model_props['Maks depth']=makdepth\n",
    "                 model_props['Min sampleing split']=minsamplesplit\n",
    "\n",
    "                 gbt=gbc(loss=los,subsample=subsample,n_estimators=makiter,min_samples_split=minsamplesplit,max_depth=makdepth,learning_rate=lurningrayt )\n",
    "\n",
    "                 auc_pr,model_perf  =self.modelling(gbt,target,target2,predictors,train,test,'GBM', model_perf_list, model_perf_,model_props,ind )\n",
    "\n",
    "                 model_perf_list.append(model_perf)\n",
    "\n",
    "                 i_=i_+1\n",
    "\n",
    "                 if(i_%1000==0):\n",
    "                               \n",
    "                     model_perf_ranking=pd.DataFrame(model_perf_list,columns=model_perf.keys())\n",
    "                     model_perf_ranking.to_csv(r'model_accuracy_gbm_'+'part_'+str(part_id)+'_'+str( rand ) +' .csv')\n",
    "                     model_perf_ranking={}\n",
    "           \n",
    "    model_perf_ranking=pd.DataFrame(model_perf_list,columns=model_perf.keys())\n",
    "    model_perf_ranking.to_csv(r'model_accuracy_gbm_'+'part_'+str(part_id)+'_'+str( rand ) +' .csv')\n",
    "    print(model_perf_ranking[0:10])\n",
    "    model_perf_ranking={}\n",
    "   \n",
    "  # GRID SEARCH ON XGBOOST\n",
    "  def gboost(self,part_id):\n",
    "\n",
    "    njobs=psutil.cpu_count()-1\n",
    "\n",
    "    model_perf_list=[]\n",
    "    model_perf={}\n",
    "    model_perf_ = {}\n",
    "\n",
    "    j_=0\n",
    "    i_=0\n",
    "\n",
    "    cnt_model=0\n",
    "    was=dt.now()\n",
    "    ind=0\n",
    "    makdepth_l=[16,12]\n",
    "    los_l=['binary:logistic']\n",
    "    subsample_l=[0.1,0.4]\n",
    "    imb_l=[0.001,0.01,0.002]\n",
    "    makftr_l=[0.1,0.5]\n",
    "    makiter_l=[1200]\n",
    "    iters_l=[1000,2000]\n",
    "    lurningrayt_l=[0.001,0.01,0.02,0.002,0.05,0.005]\n",
    "    minsamplesplit_l=[4]\n",
    "    gamma_l=[0,5]\n",
    "    makdtstp_l=[0.01,0.05,0.1]\n",
    "\n",
    "    boost_l=['gbtree','dart','gblinear']\n",
    "    colsamplebt_l=[0.5]\n",
    "    rgalp_l=[0.5]\n",
    "    rglmbd_l=[0.5]\n",
    "\n",
    "    num_iters=len(makdepth_l) * len(los_l)  * len(imb_l) *len(iters_l) *len(rglmbd_l)* len(makftr_l) * len(makiter_l) * len(subsample_l) *  len(minsamplesplit_l)  * len ( gamma_l)  * len ( lurningrayt_l)  * len(rgalp_l) *len(colsamplebt_l)  * len (makdtstp_l) * len(boost_l) * len(rglmbd_l)\n",
    "\n",
    "    for colsamplebt in colsamplebt_l:\n",
    "     for makdepth in makdepth_l:\n",
    "      for subsample in subsample_l:\n",
    "        for makftr in makftr_l:\n",
    "         for makiter in makiter_l:\n",
    "          for lurningrayt in lurningrayt_l:\n",
    "            for imb in imb_l:\n",
    "              for iters in iters_l:\n",
    "               for gamma in gamma_l:\n",
    "                for minsamplesplit in minsamplesplit_l:\n",
    "                  for makdtstp in makdtstp_l:\n",
    "                    for boost in boost_l:\n",
    "                      for lmbd in rglmbd_l:\n",
    "                       for alpha in rgalp_l:\n",
    "                           \n",
    "                        st=num_iters/(psutil.cpu_count()-2)*part_id\n",
    "                        lst=(num_iters/(psutil.cpu_count()-2))* ( 1+ part_id )\n",
    "\n",
    "                        if ( ( i_ >=st ) and ( i_ <lst ) ):\n",
    "\n",
    "                           print('st :'+str(st) + ' lst :' + str(lst))\n",
    "                           cnt_model=cnt_model+1\n",
    "                           last_=was\n",
    "                           was=dt.now()\n",
    "                           ind=ind+1\n",
    "                           print(str(cnt_model) + ' / ' + str(num_iters) + ' duration of modelling : '+ str(dt.now() -start)+ ' GBoost: ' + '  Subsample :' + str(subsample) + 'maksFiturslction : ' + str(makftr) +'makiter : '+ str(makiter) +'lurningrayt : '+str(lurningrayt) +'maksDpth:'+ str(makdepth) + 'minsamplesplit:' + str(minsamplesplit) + 'gamma :' + str(gamma) + 'alpha :' + str(alpha) + 'imbalancd wt:' + str(imb))\n",
    "                           model_props={}\n",
    "                           model_props['algo']='GBOOST'\n",
    "                           model_props['Subsampleing']=subsample\n",
    "\n",
    "                           model_props['NumTrs']=makiter\n",
    "                           model_props['Maks Fiturs']=makftr\n",
    "                           model_props['Learning rate']=lurningrayt\n",
    "                           model_props['Maks depth']=makdepth\n",
    "                           model_props['Min sampleing split']=minsamplesplit\n",
    "                           model_props['gamma']=gamma\n",
    "                           model_props['alpha']=rgalp_l\n",
    "                           model_props['imb']=imb\n",
    "                           model_props['boostr']=boost\n",
    "                           model_props['colsamplebyTr']=colsamplebt\n",
    "                           model_props['maks dlta stp']=makdtstp\n",
    "\n",
    "                           gbst =  XGBClassifier( max_depth=makdepth, objective='binary:logistic' , scale_pos_weight=imb ,  booster=boost , learning_rate=lurningrayt , min_child_weight=makftr , colsamplebytree=colsamplebt , reg_alpha=alpha , gamma= gamma , reg_lambda=lmbd )\n",
    "\n",
    "                           auc_pr,model_perf=self.modelling(gbst, target , target2 , predictors , train ,test , 'GBoost' , model_perf_list,model_perf_, model_props,ind)\n",
    "\n",
    "                           model_perf_list.append(model_perf)\n",
    "\n",
    "                        i_ = i_ +1\n",
    "                        \n",
    "                        if(i_%1000==0):\n",
    "\n",
    "                              model_perf_ranking=pd.DataFrame(model_perf_list,columns=model_perf.keys())\n",
    "\n",
    "                              model_perf_ranking.to_csv(r'model_accuracy_gboost_'+'part_'+str(part_id)+'_'+str( rand )+' .csv')\n",
    "                              \n",
    "                              model_perf_ranking={}\n",
    "  \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "            Feature Importance From Random Forest\n",
    "            \n",
    "             \n",
    "\t  'relationship'              0.15417    \n",
    "      'capital_gain'              0.14262     \n",
    "      'marital_status'            0.12675     \n",
    "      'education_num'             0.10298    \n",
    "      'age'                       0.08588     \n",
    "      'date_of_birth'             0.06169     \n",
    "      'hours_per_week'            0.04874     \n",
    "      'education_level'           0.03426     \n",
    "      'occupation'                0.03330     \n",
    "      'inquiry_purpose_code'      0.03099     \n",
    "      'address'                   0.02673  \n",
    "      'email'                     0.02618    \n",
    "      'capital_loss'              0.02380     \n",
    "      'state'                     0.02232     \n",
    "      'gender'                    0.01786     \n",
    "      'mail_accnt'                0.01724     \n",
    "      'workclass'                 0.01024    \n",
    "      'account_type'              0.00976     \n",
    "      'institute_type'            0.00703     \n",
    "      'house_type'                0.00694    \n",
    "      'asset_class_cd'            0.00504   \n",
    "      'portfolio_type'            0.00488    \n",
    "      'asset_code'                0.00050   \n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialisation stage \n",
      " data loading and sanity checks \n",
      "C:/Users/lenovo/Documents/Assignment 1/config.json\n",
      "loading input dataset\n",
      "                                user_id   gender date_of_birth  \\\n",
      "0  307c73a3-0c67-43b5-b0d1-62ad5f00b52a   Female    1987-01-03   \n",
      "1  519481f1-604d-48b6-aa47-4123a982431a     Male    1970-01-07   \n",
      "2  f66fe2c6-53e3-46ce-8321-e530b4af1ace     Male    1973-01-06   \n",
      "3  91360ed7-72d1-4f6e-b492-d71ef4480061   Female    2001-12-30   \n",
      "4  0e1977f3-3bef-4283-8d0a-d60b0f6ff480     Male    1986-01-03   \n",
      "5  3c8fbbaf-cd9d-4e17-8cd4-fc7c01eb9203   Female    1956-01-11   \n",
      "6  27256e97-6bae-4ce6-9b80-58fb66a3d452   Female    2001-12-30   \n",
      "7  745b9022-fe0e-4d8e-8056-96f56613260f   Female    1996-12-31   \n",
      "8  9b56df25-024a-47fe-b895-70317c7b63ce     Male    1977-01-05   \n",
      "9  3257eeda-137c-4d8c-a295-b497a3211a48   Female    1963-01-09   \n",
      "\n",
      "           workclass education_level  education_num       marital_status  \\\n",
      "0            Private            11th            7.0        Never-married   \n",
      "1   Self-emp-not-inc    Some-college           10.0   Married-civ-spouse   \n",
      "2            Private         HS-grad            9.0             Divorced   \n",
      "3            Private            11th            7.0        Never-married   \n",
      "4            Private    Some-college           10.0   Married-civ-spouse   \n",
      "5            Private         HS-grad            9.0              Widowed   \n",
      "6            Private         HS-grad            9.0        Never-married   \n",
      "7            Private    Some-college           10.0        Never-married   \n",
      "8            Private         Masters           14.0   Married-civ-spouse   \n",
      "9          State-gov            12th            8.0             Divorced   \n",
      "\n",
      "           occupation    relationship  capital_gain  ...  hours_per_week  \\\n",
      "0               Sales       Unmarried           0.0  ...            17.0   \n",
      "1        Craft-repair         Husband           0.0  ...            48.0   \n",
      "2               Sales   Not-in-family           0.0  ...            50.0   \n",
      "3               Sales       Own-child           0.0  ...            15.0   \n",
      "4   Handlers-cleaners         Husband           0.0  ...            50.0   \n",
      "5        Adm-clerical       Unmarried           0.0  ...             8.0   \n",
      "6               Sales       Own-child           0.0  ...            24.0   \n",
      "7     Farming-fishing   Not-in-family           0.0  ...            50.0   \n",
      "8     Exec-managerial         Husband           0.0  ...            45.0   \n",
      "9       Other-service       Unmarried           0.0  ...            40.0   \n",
      "\n",
      "   approved                                            address  \\\n",
      "0         0  45424 Norris Common Apt. 390\\nNorth Mike, AR 8...   \n",
      "1         0  5022 Rebecca Haven Apt. 258\\nThompsonfurt, CT ...   \n",
      "2         0    8780 Brown Loaf Apt. 099\\nNorth David, NJ 56510   \n",
      "3         0  721 Jackson Extensions Suite 995\\nNew Taraside...   \n",
      "4         0         935 Burch Divide\\nLake Bobbyfurt, VT 14128   \n",
      "5         0          93533 Moore Greens\\nWest Alicia, NC 34941   \n",
      "6         0  90598 Richardson Mountains Apt. 192\\nJohnsonfu...   \n",
      "7         0  28328 Bradley Views Suite 367\\nSmithport, AK 5...   \n",
      "8         0  47303 Sarah Freeway Suite 045\\nLake Mariaborou...   \n",
      "9         0    7536 Davis Street Suite 960\\nLuisfort, VA 25279   \n",
      "\n",
      "                         email inquiry_purpose_code institute_type  \\\n",
      "0        vasquezleah@yahoo.com                    7            PVT   \n",
      "1    johnsontrevor@hotmail.com                   13            NBF   \n",
      "2        morganemily@gmail.com                   13            NBF   \n",
      "3          agarcia@hotmail.com                   13            NBF   \n",
      "4    shermanmeredith@gmail.com                   13            PVT   \n",
      "5  frostvictor@west-barron.biz                   99            NBF   \n",
      "6         calvin66@hotmail.com                   14            HFC   \n",
      "7            bwalker@yahoo.com                   13            PVT   \n",
      "8           rperkins@yahoo.com                   10            PVT   \n",
      "9     emilymiller@martinez.com                    7            PVT   \n",
      "\n",
      "  account_type  asset_class_cd asset_code portfolio_type  \n",
      "0            5                          1              R  \n",
      "1            5                          1              R  \n",
      "2            5                          1              R  \n",
      "3            5                          1              R  \n",
      "4           47               S          1              I  \n",
      "5            5                          1              R  \n",
      "6            5                          1              R  \n",
      "7            5                          1              R  \n",
      "8            5                          1              R  \n",
      "9            5                          1              R  \n",
      "\n",
      "[10 rows x 21 columns]\n",
      "(45222, 21)\n",
      " Feature Engineering \n",
      "target variable:approved\n",
      "feature distribution with respect to Target variable: Approved\n",
      "0    34014\n",
      "1    11208\n",
      "Name: approved, dtype: int64\n",
      "Chi2 test on Target and Feature Distribution\n",
      "\n",
      "\n",
      "\n",
      " FEATURE :user_id\n",
      "approved                              0  1\n",
      "user_id                                   \n",
      "0001485b-52ab-455b-8f9e-3f8a741af340  1  0\n",
      "0003d403-6df8-4fe6-9056-2efd30902455  1  0\n",
      "0005a082-0328-4bb4-8de1-c3a34960bd9c  1  0\n",
      "0005df24-538f-4910-a9e8-abdac09d9adf  0  1\n",
      "00084b04-5e10-4bf9-8948-b7bf7557d5f4  1  0\n",
      "...                                  .. ..\n",
      "fff8add7-264a-4e53-9c23-6ea374757fab  1  0\n",
      "fffad5cd-10ef-4b0b-b74a-a922ebe45e96  1  0\n",
      "fffb0eae-57d1-4e99-a19d-529d230f5934  0  1\n",
      "fffb60cb-e1f3-4dfd-abb8-373f5cc8e353  0  1\n",
      "fffd17ef-7537-407a-886b-207f92f7879e  1  0\n",
      "\n",
      "[45222 rows x 2 columns]\n",
      "Chi2 test on Target and Feature Distribution\n",
      "From chi2 Statistic probability=0.950, critical=45716.80073, stat=45222.00000\n",
      "Independent (fail to reject H0) \n",
      "From Test significance=0.05000, p=0.49779\n",
      "Independent (fail to reject H0)\n",
      "\n",
      "\n",
      "\n",
      " FEATURE :gender\n",
      "approved      0     1\n",
      "gender               \n",
      " Female   13026  1669\n",
      " Male     20988  9539\n",
      "Chi2 test on Target and Feature Distribution\n",
      "From chi2 Statistic probability=0.950, critical=3.84146, stat=2104.13372\n",
      "Dependent (reject H0)\n",
      "From Test significance=0.05000, p=0.00000\n",
      "Dependent (reject H0)\n",
      "\n",
      "\n",
      "\n",
      " FEATURE :date_of_birth\n",
      "approved         0   1\n",
      "date_of_birth         \n",
      "1930-01-17      34  12\n",
      "1931-01-17       1   0\n",
      "1932-01-17       4   1\n",
      "1933-01-16       1   0\n",
      "1934-01-16       1   0\n",
      "...            ...  ..\n",
      "1998-12-31     929   6\n",
      "1999-12-31     915   1\n",
      "2000-12-30     862   2\n",
      "2001-12-30     695   0\n",
      "2002-12-30     493   0\n",
      "\n",
      "[74 rows x 2 columns]\n",
      "Chi2 test on Target and Feature Distribution\n",
      "From chi2 Statistic probability=0.950, critical=93.94534, stat=4685.91752\n",
      "Dependent (reject H0)\n",
      "From Test significance=0.05000, p=0.00000\n",
      "Dependent (reject H0)\n",
      "\n",
      "\n",
      "\n",
      " FEATURE :workclass\n",
      "approved               0     1\n",
      "workclass                     \n",
      " Federal-gov         857   549\n",
      " Local-gov          2185   915\n",
      " Private           26056  7251\n",
      " Self-emp-inc        734   912\n",
      " Self-emp-not-inc   2737  1059\n",
      " State-gov          1426   520\n",
      " Without-pay          19     2\n",
      "Chi2 test on Target and Feature Distribution\n",
      "From chi2 Statistic probability=0.950, critical=12.59159, stat=1207.25991\n",
      "Dependent (reject H0)\n",
      "From Test significance=0.05000, p=0.00000\n",
      "Dependent (reject H0)\n",
      "\n",
      "\n",
      "\n",
      " FEATURE :education_level\n",
      "approved             0     1\n",
      "education_level             \n",
      " 10th             1141    82\n",
      " 11th             1530    89\n",
      " 12th              534    43\n",
      " 1st-4th           214     8\n",
      " 5th-6th           427    22\n",
      " 7th-8th           768    55\n",
      " 9th               638    38\n",
      " Assoc-acdm       1109   398\n",
      " Assoc-voc        1455   504\n",
      " Bachelors        4392  3178\n",
      " Doctorate         145   399\n",
      " HS-grad         12367  2416\n",
      " Masters          1121  1393\n",
      " Preschool          71     1\n",
      " Prof-school       193   592\n",
      " Some-college     7909  1990\n",
      "Chi2 test on Target and Feature Distribution\n",
      "From chi2 Statistic probability=0.950, critical=24.99579, stat=5996.00303\n",
      "Dependent (reject H0)\n",
      "From Test significance=0.05000, p=0.00000\n",
      "Dependent (reject H0)\n",
      "\n",
      "\n",
      "\n",
      " FEATURE :education_num\n",
      "approved           0     1\n",
      "education_num             \n",
      "1.0               71     1\n",
      "2.0              214     8\n",
      "3.0              427    22\n",
      "4.0              768    55\n",
      "5.0              638    38\n",
      "6.0             1141    82\n",
      "7.0             1530    89\n",
      "8.0              534    43\n",
      "9.0            12367  2416\n",
      "10.0            7909  1990\n",
      "11.0            1455   504\n",
      "12.0            1109   398\n",
      "13.0            4392  3178\n",
      "14.0            1121  1393\n",
      "15.0             193   592\n",
      "16.0             145   399\n",
      "Chi2 test on Target and Feature Distribution\n",
      "From chi2 Statistic probability=0.950, critical=24.99579, stat=5996.00303\n",
      "Dependent (reject H0)\n",
      "From Test significance=0.05000, p=0.00000\n",
      "Dependent (reject H0)\n",
      "\n",
      "\n",
      "\n",
      " FEATURE :marital_status\n",
      "approved                    0     1\n",
      "marital_status                     \n",
      " Divorced                5642   655\n",
      " Married-AF-spouse         18    14\n",
      " Married-civ-spouse     11491  9564\n",
      " Married-spouse-absent    498    54\n",
      " Never-married          13897   701\n",
      " Separated               1312    99\n",
      " Widowed                 1156   121\n",
      "Chi2 test on Target and Feature Distribution\n",
      "From chi2 Statistic probability=0.950, critical=12.59159, stat=9109.22988\n",
      "Dependent (reject H0)\n",
      "From Test significance=0.05000, p=0.00000\n",
      "Dependent (reject H0)\n",
      "\n",
      "\n",
      "\n",
      " FEATURE :occupation\n",
      "approved               0     1\n",
      "occupation                    \n",
      " Adm-clerical       4784   756\n",
      " Armed-Forces         10     4\n",
      " Craft-repair       4665  1355\n",
      " Exec-managerial    3117  2867\n",
      " Farming-fishing    1308   172\n",
      " Handlers-cleaners  1911   135\n",
      " Machine-op-inspct  2605   365\n",
      " Other-service      4612   196\n",
      " Priv-house-serv     229     3\n",
      " Prof-specialty     3304  2704\n",
      " Protective-serv     669   307\n",
      " Sales              3953  1455\n",
      " Tech-support       1009   411\n",
      " Transport-moving   1838   478\n",
      "Chi2 test on Target and Feature Distribution\n",
      "From chi2 Statistic probability=0.950, critical=22.36203, stat=5415.13777\n",
      "Dependent (reject H0)\n",
      "From Test significance=0.05000, p=0.00000\n",
      "Dependent (reject H0)\n",
      "\n",
      "\n",
      "\n",
      " FEATURE :relationship\n",
      "approved             0     1\n",
      "relationship                \n",
      " Husband         10159  8507\n",
      " Not-in-family   10474  1228\n",
      " Other-relative   1299    50\n",
      " Own-child        6521   105\n",
      " Unmarried        4486   302\n",
      " Wife             1075  1016\n",
      "Chi2 test on Target and Feature Distribution\n",
      "From chi2 Statistic probability=0.950, critical=11.07050, stat=9357.03667\n",
      "Dependent (reject H0)\n",
      "From Test significance=0.05000, p=0.00000\n",
      "Dependent (reject H0)\n",
      "\n",
      "\n",
      "\n",
      " FEATURE :capital_gain\n",
      "approved          0     1\n",
      "capital_gain             \n",
      "0.0           32599  8833\n",
      "114.0             8     0\n",
      "401.0             2     0\n",
      "594.0            42     0\n",
      "914.0            10     0\n",
      "...             ...   ...\n",
      "25236.0           0    14\n",
      "27828.0           0    56\n",
      "34095.0           4     0\n",
      "41310.0           3     0\n",
      "99999.0           0   229\n",
      "\n",
      "[121 rows x 2 columns]\n",
      "Chi2 test on Target and Feature Distribution\n",
      "From chi2 Statistic probability=0.950, critical=146.56736, stat=7827.99238\n",
      "Dependent (reject H0)\n",
      "From Test significance=0.05000, p=0.00000\n",
      "Dependent (reject H0)\n",
      "\n",
      "\n",
      "\n",
      " FEATURE :capital_loss\n",
      "approved          0      1\n",
      "capital_loss              \n",
      "0.0           32972  10110\n",
      "155.0             1      0\n",
      "213.0             5      0\n",
      "323.0             5      0\n",
      "419.0             1      0\n",
      "...             ...    ...\n",
      "3175.0            2      0\n",
      "3683.0            1      1\n",
      "3770.0            4      0\n",
      "3900.0            2      0\n",
      "4356.0            1      0\n",
      "\n",
      "[97 rows x 2 columns]\n",
      "Chi2 test on Target and Feature Distribution\n",
      "From chi2 Statistic probability=0.950, critical=119.87094, stat=3459.05496\n",
      "Dependent (reject H0)\n",
      "From Test significance=0.05000, p=0.00000\n",
      "Dependent (reject H0)\n",
      "\n",
      "\n",
      "\n",
      " FEATURE :hours_per_week\n",
      "approved         0   1\n",
      "hours_per_week        \n",
      "1.0             10   2\n",
      "2.0             21   3\n",
      "3.0             33   2\n",
      "4.0             42   5\n",
      "5.0             52   8\n",
      "...             ..  ..\n",
      "95.0             1   1\n",
      "96.0             8   1\n",
      "97.0             1   1\n",
      "98.0            11   3\n",
      "99.0            83  40\n",
      "\n",
      "[96 rows x 2 columns]\n",
      "Chi2 test on Target and Feature Distribution\n",
      "From chi2 Statistic probability=0.950, critical=118.75161, stat=3529.88003\n",
      "Dependent (reject H0)\n",
      "From Test significance=0.05000, p=0.00000\n",
      "Dependent (reject H0)\n",
      "\n",
      "\n",
      "\n",
      " FEATURE :approved\n",
      "approved      0      1\n",
      "approved              \n",
      "0         34014      0\n",
      "1             0  11208\n",
      "Chi2 test on Target and Feature Distribution\n",
      "From chi2 Statistic probability=0.950, critical=3.84146, stat=45216.63585\n",
      "Dependent (reject H0)\n",
      "From Test significance=0.05000, p=0.00000\n",
      "Dependent (reject H0)\n",
      "\n",
      "\n",
      "\n",
      " FEATURE :address\n",
      "approved                                            0  1\n",
      "address                                                 \n",
      "000 Adams Knoll Suite 160\\nSouth Heatherburgh, ...  1  0\n",
      "000 Catherine Circle\\nSouth Nicole, SD 97980        1  0\n",
      "000 Coleman Islands\\nBennettmouth, VA 79143         0  1\n",
      "000 Harrington Expressway Suite 949\\nNew Justin...  1  0\n",
      "000 Harrington Trail Apt. 664\\nEast Paulfort, N...  1  0\n",
      "...                                                .. ..\n",
      "Unit 9949 Box 6197\\nDPO AE 24622                    0  1\n",
      "Unit 9965 Box 1764\\nDPO AA 81606                    1  0\n",
      "Unit 9965 Box 2433\\nDPO AE 14838                    1  0\n",
      "Unit 9982 Box 1434\\nDPO AE 76983                    1  0\n",
      "Unit 9997 Box 9236\\nDPO AP 30692                    1  0\n",
      "\n",
      "[45222 rows x 2 columns]\n",
      "Chi2 test on Target and Feature Distribution\n",
      "From chi2 Statistic probability=0.950, critical=45716.80073, stat=45222.00000\n",
      "Independent (fail to reject H0) \n",
      "From Test significance=0.05000, p=0.49779\n",
      "Independent (fail to reject H0)\n",
      "\n",
      "\n",
      "\n",
      " FEATURE :email\n",
      "approved                  0  1\n",
      "email                         \n",
      "aabbott@hotmail.com       1  0\n",
      "aadams@taylor.com         1  0\n",
      "aaguilar@hotmail.com      0  1\n",
      "aaguirre@hotmail.com      0  1\n",
      "aalexander@arroyo.net     1  0\n",
      "...                      .. ..\n",
      "zwoodward@gmail.com       1  0\n",
      "zwright@gmail.com         0  1\n",
      "zwright@murphy-adams.net  0  1\n",
      "zwright@yahoo.com         0  1\n",
      "zyork@gmail.com           1  0\n",
      "\n",
      "[44300 rows x 2 columns]\n",
      "Chi2 test on Target and Feature Distribution\n",
      "From chi2 Statistic probability=0.950, critical=44789.73192, stat=44275.73608\n",
      "Independent (fail to reject H0) \n",
      "From Test significance=0.05000, p=0.53026\n",
      "Independent (fail to reject H0)\n",
      "\n",
      "\n",
      "\n",
      " FEATURE :inquiry_purpose_code\n",
      "approved                  0     1\n",
      "inquiry_purpose_code             \n",
      "                       1062   229\n",
      "01                       49     5\n",
      "02                      160    23\n",
      "03                       15     2\n",
      "04                       11     2\n",
      "06                        2     1\n",
      "07                       69    23\n",
      "08                       11     3\n",
      "1                       269    30\n",
      "10                      169    14\n",
      "11                      103     7\n",
      "12                        2     2\n",
      "13                    16916  3578\n",
      "14                      607   501\n",
      "16                     2805   731\n",
      "17                       18     3\n",
      "18                        7     0\n",
      "2                      1813   438\n",
      "3                        95    12\n",
      "4                        24     3\n",
      "5                        97    29\n",
      "6                       408    68\n",
      "7                      3228  2551\n",
      "8                       130    28\n",
      "9                         6     1\n",
      "99                     5938  2924\n",
      "Chi2 test on Target and Feature Distribution\n",
      "From chi2 Statistic probability=0.950, critical=37.65248, stat=2579.89902\n",
      "Dependent (reject H0)\n",
      "From Test significance=0.05000, p=0.00000\n",
      "Dependent (reject H0)\n",
      "\n",
      "\n",
      "\n",
      " FEATURE :institute_type\n",
      "approved            0     1\n",
      "institute_type             \n",
      "BRO               174   129\n",
      "COB                28     7\n",
      "FOR                79    28\n",
      "HFC               731   175\n",
      "INS                33     8\n",
      "NBF             12889  3038\n",
      "PUB               961   265\n",
      "PVT             19111  7558\n",
      "SRC                 4     0\n",
      "TEL                 4     0\n",
      "Chi2 test on Target and Feature Distribution\n",
      "From chi2 Statistic probability=0.950, critical=16.91898, stat=535.78029\n",
      "Dependent (reject H0)\n",
      "From Test significance=0.05000, p=0.00000\n",
      "Dependent (reject H0)\n",
      "\n",
      "\n",
      "\n",
      " FEATURE :account_type\n",
      "approved          0     1\n",
      "account_type             \n",
      "5             19483  7321\n",
      "47             1198   250\n",
      "58              722   422\n",
      "121             302    47\n",
      "123            2116   478\n",
      "130             814   211\n",
      "167               7     1\n",
      "168               2     0\n",
      "170               5     0\n",
      "172              58     8\n",
      "173            1189   228\n",
      "175               4     0\n",
      "176             114     8\n",
      "177             126    14\n",
      "178             164    10\n",
      "179              31     2\n",
      "181              10     5\n",
      "184             137    32\n",
      "185              27     4\n",
      "187              12     0\n",
      "189            5401  1798\n",
      "191            1097   168\n",
      "195              52    21\n",
      "197               4     0\n",
      "198               4     1\n",
      "213              21    19\n",
      "214               1     0\n",
      "220               2     0\n",
      "221              22    10\n",
      "222               2     0\n",
      "223               5     1\n",
      "224             118     2\n",
      "226              18     4\n",
      "227              98     3\n",
      "228               8     3\n",
      "240               4     7\n",
      "999             636   130\n",
      "Chi2 test on Target and Feature Distribution\n",
      "From chi2 Statistic probability=0.950, critical=50.99846, stat=671.57648\n",
      "Dependent (reject H0)\n",
      "From Test significance=0.05000, p=0.00000\n",
      "Dependent (reject H0)\n",
      "\n",
      "\n",
      "\n",
      " FEATURE :asset_class_cd\n",
      "approved            0     1\n",
      "asset_class_cd             \n",
      "                26210  9520\n",
      "-1                  1     0\n",
      "01                  0     1\n",
      "?                 224    95\n",
      "B                 224     6\n",
      "D                 104     6\n",
      "L                 137     7\n",
      "M                  74     4\n",
      "S                7040  1569\n",
      "Chi2 test on Target and Feature Distribution\n",
      "From chi2 Statistic probability=0.950, critical=15.50731, stat=402.17652\n",
      "Dependent (reject H0)\n",
      "From Test significance=0.05000, p=0.00000\n",
      "Dependent (reject H0)\n",
      "\n",
      "\n",
      "\n",
      " FEATURE :asset_code\n",
      "approved        0      1\n",
      "asset_code              \n",
      "               59     23\n",
      "1           32859  10856\n",
      "19             43     19\n",
      "2             882    282\n",
      "4             171     28\n",
      "Chi2 test on Target and Feature Distribution\n",
      "From chi2 Statistic probability=0.950, critical=9.48773, stat=14.11587\n",
      "Dependent (reject H0)\n",
      "From Test significance=0.05000, p=0.00693\n",
      "Dependent (reject H0)\n",
      "\n",
      "\n",
      "\n",
      " FEATURE :portfolio_type\n",
      "approved            0     1\n",
      "portfolio_type             \n",
      "                    5     1\n",
      "F                  14     1\n",
      "I               13646  3442\n",
      "M                 724   422\n",
      "R               19625  7342\n",
      "Chi2 test on Target and Feature Distribution\n",
      "From chi2 Statistic probability=0.950, critical=9.48773, stat=375.67535\n",
      "Dependent (reject H0)\n",
      "From Test significance=0.05000, p=0.00000\n",
      "Dependent (reject H0)\n",
      "\n",
      "\n",
      "\n",
      " FEATURE :age\n",
      "approved    0   1\n",
      "age              \n",
      "6361      493   0\n",
      "6726      695   0\n",
      "7091      862   2\n",
      "7456      915   1\n",
      "7821      929   6\n",
      "...       ...  ..\n",
      "31546       1   0\n",
      "31911       1   0\n",
      "32276       4   1\n",
      "32641       1   0\n",
      "33006      34  12\n",
      "\n",
      "[74 rows x 2 columns]\n",
      "Chi2 test on Target and Feature Distribution\n",
      "From chi2 Statistic probability=0.950, critical=93.94534, stat=4685.91752\n",
      "Dependent (reject H0)\n",
      "From Test significance=0.05000, p=0.00000\n",
      "Dependent (reject H0)\n",
      "\n",
      "\n",
      "\n",
      " FEATURE :state\n",
      "approved     0    1\n",
      "state              \n",
      "AA        1166  396\n",
      "AE        1206  399\n",
      "AK         590  199\n",
      "AL         615  182\n",
      "AP        1252  398\n",
      "AR         580  226\n",
      "AZ         606  198\n",
      "CA         636  182\n",
      "CO         536  181\n",
      "CT         568  192\n",
      "DC         597  193\n",
      "DE         582  189\n",
      "FL         567  208\n",
      "GA         596  203\n",
      "HI         623  202\n",
      "IA         586  190\n",
      "ID         609  200\n",
      "IL         568  174\n",
      "IN         606  222\n",
      "KS         621  182\n",
      "KY         603  174\n",
      "LA         585  186\n",
      "MA         574  207\n",
      "MD         579  183\n",
      "ME         636  182\n",
      "MI         600  205\n",
      "MN         559  204\n",
      "MO         617  204\n",
      "MS         641  186\n",
      "MT         576  180\n",
      "NC         548  188\n",
      "ND         586  186\n",
      "NE         614  187\n",
      "NH         591  204\n",
      "NJ         623  190\n",
      "NM         561  183\n",
      "NV         567  208\n",
      "NY         664  214\n",
      "OH         640  198\n",
      "OK         598  196\n",
      "OR         592  224\n",
      "PA         571  191\n",
      "RI         622  163\n",
      "SC         612  211\n",
      "SD         573  212\n",
      "TN         623  177\n",
      "TX         554  186\n",
      "UT         623  201\n",
      "VA         564  198\n",
      "VT         577  205\n",
      "WA         620  205\n",
      "WI         606  220\n",
      "WV         576  220\n",
      "WY         629  214\n",
      "Chi2 test on Target and Feature Distribution\n",
      "From chi2 Statistic probability=0.950, critical=70.99345, stat=54.92747\n",
      "Independent (fail to reject H0) \n",
      "From Test significance=0.05000, p=0.40145\n",
      "Independent (fail to reject H0)\n",
      "\n",
      "\n",
      "\n",
      " FEATURE :mail_accnt\n",
      "approved       0  1\n",
      "mail_accnt         \n",
      "abbott.biz     1  1\n",
      "abbott.com     5  0\n",
      "abbott.info    1  0\n",
      "abbott.net     2  1\n",
      "abbott.org     2  1\n",
      "...           .. ..\n",
      "zimmerman.com  3  1\n",
      "zimmerman.org  0  1\n",
      "zuniga.com     2  0\n",
      "zuniga.net     1  0\n",
      "zuniga.org     1  0\n",
      "\n",
      "[3478 rows x 2 columns]\n",
      "Chi2 test on Target and Feature Distribution\n",
      "From chi2 Statistic probability=0.950, critical=3615.29299, stat=3564.99181\n",
      "Independent (fail to reject H0) \n",
      "From Test significance=0.05000, p=0.14585\n",
      "Independent (fail to reject H0)\n",
      "\n",
      "\n",
      "\n",
      " FEATURE :house_type\n",
      "approved        0     1\n",
      "house_type             \n",
      "Apt          7665  2576\n",
      "Studio       7513  2516\n",
      "others      18836  6116\n",
      "Chi2 test on Target and Feature Distribution\n",
      "From chi2 Statistic probability=0.950, critical=5.99146, stat=2.24308\n",
      "Independent (fail to reject H0) \n",
      "From Test significance=0.05000, p=0.32578\n",
      "Independent (fail to reject H0)\n",
      " TRAIN DATA TARGET DISTRIBUTION \n",
      "0    27211\n",
      "1     8966\n",
      "Name: approved, dtype: int64\n",
      " TEST DATA TARGET DISTRIBUTION \n",
      "0    6803\n",
      "1    2242\n",
      "Name: alt_flag, dtype: int64\n",
      "0 / 18432 duration for modelling : 0:00:00 till is : 1 day, 17:15:51.169570  DT : minsamplelf  4 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.01\n",
      "1 / 18432 duration for modelling : 0:00:00.399893 till is : 1 day, 17:15:51.569463  DT : minsamplelf  4 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.001\n",
      "2 / 18432 duration for modelling : 0:00:00.515867 till is : 1 day, 17:15:52.085330  DT : minsamplelf  4 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.02\n",
      "3 / 18432 duration for modelling : 0:00:00.339910 till is : 1 day, 17:15:52.425240  DT : minsamplelf  4 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.002\n",
      "4 / 18432 duration for modelling : 0:00:00.435890 till is : 1 day, 17:15:52.861130  DT : minsamplelf  4 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.005\n",
      "currnt:\n",
      "\n",
      "\n",
      " MODEL {'algo': 'DT', 'Maks Fiturs': 0.2, 'criteria': 'gini', 'Min Sample leaf': 4, 'Maks depth': 16, 'Min sampleing split': 4, 'class weight': 'None', ' Min Impurity decrease ': 0.005}\n",
      " TP 904\n",
      " FP 358\n",
      " FN 1338\n",
      " TN 6445\n",
      " PRECISION 0.7157561361836896\n",
      " RECALL 0.40303165403477487\n",
      " F1 0.13614972711444034\n",
      " auc roc 0.7220927155635146\n",
      " auc pr 0.48667911801047264\n",
      " Balanced Error Rate 0.2779072844364854\n",
      " Features and contributions :\n",
      "Avg Probability of Y : 0.35562011348379446\n",
      "Avg Probability of N : 0.16455208246097855\n",
      "Min Probability of Y : 0.08988960925179604\n",
      "Top Probability of Y : 0.735593220338983\n",
      " top model \n",
      "\n",
      "\n",
      " MODEL {'algo': 'DT', 'Maks Fiturs': 0.2, 'criteria': 'gini', 'Min Sample leaf': 4, 'Maks depth': 16, 'Min sampleing split': 4, 'class weight': 'None', ' Min Impurity decrease ': 0.001}\n",
      " TP 741\n",
      " FP 251\n",
      " FN 1501\n",
      " TN 6552\n",
      " PRECISION 0.7462235649546828\n",
      " RECALL 0.33036112349531876\n",
      " F1 0.11871572426989249\n",
      " auc roc 0.8304748403620535\n",
      " auc pr 0.5969066579810244\n",
      " Balanced Error Rate 0.16952515963794645\n",
      " Features and contributions :\n",
      "Avg Probability of Y : 0.4436099040788149\n",
      "Avg Probability of N : 0.1610810591588204\n",
      "Min Probability of Y : 0.058624440952496075\n",
      "Top Probability of Y : 0.7908496732026143\n",
      "5 / 18432 duration for modelling : 0:00:00.371904 till is : 1 day, 17:15:53.233034  DT : minsamplelf  4 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.05\n",
      "6 / 18432 duration for modelling : 0:00:00.223944 till is : 1 day, 17:15:53.456978  DT : minsamplelf  4 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.01\n",
      "7 / 18432 duration for modelling : 0:00:00.427894 till is : 1 day, 17:15:53.884872  DT : minsamplelf  4 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.001\n",
      "8 / 18432 duration for modelling : 0:00:00.499868 till is : 1 day, 17:15:54.384740  DT : minsamplelf  4 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.02\n",
      "9 / 18432 duration for modelling : 0:00:00.435894 till is : 1 day, 17:15:54.820634  DT : minsamplelf  4 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.002\n",
      "currnt:\n",
      "\n",
      "\n",
      " MODEL {'algo': 'DT', 'Maks Fiturs': 0.2, 'criteria': 'entropy', 'Min Sample leaf': 4, 'Maks depth': 16, 'Min sampleing split': 4, 'class weight': 'None', ' Min Impurity decrease ': 0.002}\n",
      " TP 1224\n",
      " FP 596\n",
      " FN 1018\n",
      " TN 6207\n",
      " PRECISION 0.6721581548599671\n",
      " RECALL 0.5456977262594739\n",
      " F1 0.16538278249563768\n",
      " auc roc 0.8507004767666257\n",
      " auc pr 0.5772847328988274\n",
      " Balanced Error Rate 0.14929952323337425\n",
      " Features and contributions :\n",
      "Avg Probability of Y : 0.429311598017279\n",
      "Avg Probability of N : 0.14444167736247485\n",
      "Min Probability of Y : 0.01205519244734931\n",
      "Top Probability of Y : 0.6045627376425855\n",
      " top model \n",
      "\n",
      "\n",
      " MODEL {'algo': 'DT', 'Maks Fiturs': 0.2, 'criteria': 'entropy', 'Min Sample leaf': 4, 'Maks depth': 16, 'Min sampleing split': 4, 'class weight': 'balanced', 'Min Impurity decrease ': 0.001}\n",
      " TP 1783\n",
      " FP 1456\n",
      " FN 459\n",
      " TN 5347\n",
      " PRECISION 0.5503086419753086\n",
      " RECALL 0.7949175211769951\n",
      " F1 0.18652784470615763\n",
      " auc roc 0.8657194974720578\n",
      " auc pr 0.6486755000247012\n",
      " Balanced Error Rate 0.1342805025279422\n",
      " Features and contributions :\n",
      "Avg Probability of Y : 0.6736988844221286\n",
      "Avg Probability of N : 0.27887423161372543\n",
      "Min Probability of Y : 0.006081557822851374\n",
      "Top Probability of Y : 0.9238944062473473\n",
      "10 / 18432 duration for modelling : 0:00:00.455879 till is : 1 day, 17:15:55.276513  DT : minsamplelf  4 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.005\n",
      "11 / 18432 duration for modelling : 0:00:00.347915 till is : 1 day, 17:15:55.624428  DT : minsamplelf  4 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.05\n",
      "12 / 18432 duration for modelling : 0:00:00.299923 till is : 1 day, 17:15:55.924351  DT : minsamplelf  5 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.01\n",
      "13 / 18432 duration for modelling : 0:00:00.211943 till is : 1 day, 17:15:56.136294  DT : minsamplelf  5 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.001\n",
      "14 / 18432 duration for modelling : 0:00:00.655843 till is : 1 day, 17:15:56.792137  DT : minsamplelf  5 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.02\n",
      "currnt:\n",
      "\n",
      "\n",
      " MODEL {'algo': 'DT', 'Maks Fiturs': 0.2, 'criteria': 'gini', 'Min Sample leaf': 5, 'Maks depth': 16, 'Min sampleing split': 4, 'class weight': 'None', ' Min Impurity decrease ': 0.02}\n",
      " TP 801\n",
      " FP 304\n",
      " FN 1441\n",
      " TN 6499\n",
      " PRECISION 0.7242314647377939\n",
      " RECALL 0.3571110120374498\n",
      " F1 0.12426164084374607\n",
      " auc roc 0.775354296780701\n",
      " auc pr 0.5084514004956275\n",
      " Balanced Error Rate 0.224645703219299\n",
      " Features and contributions :\n",
      "Avg Probability of Y : 0.42438505639197105\n",
      "Avg Probability of N : 0.18968339135157009\n",
      "Min Probability of Y : 0.10336719337848006\n",
      "Top Probability of Y : 0.7302793296089386\n",
      " top model \n",
      "\n",
      "\n",
      " MODEL {'algo': 'DT', 'Maks Fiturs': 0.2, 'criteria': 'entropy', 'Min Sample leaf': 4, 'Maks depth': 16, 'Min sampleing split': 4, 'class weight': 'balanced', 'Min Impurity decrease ': 0.001}\n",
      " TP 1783\n",
      " FP 1456\n",
      " FN 459\n",
      " TN 5347\n",
      " PRECISION 0.5503086419753086\n",
      " RECALL 0.7949175211769951\n",
      " F1 0.18652784470615763\n",
      " auc roc 0.8657194974720578\n",
      " auc pr 0.6486755000247012\n",
      " Balanced Error Rate 0.1342805025279422\n",
      " Features and contributions :\n",
      "Avg Probability of Y : 0.6736988844221286\n",
      "Avg Probability of N : 0.27887423161372543\n",
      "Min Probability of Y : 0.006081557822851374\n",
      "Top Probability of Y : 0.9238944062473473\n",
      "15 / 18432 duration for modelling : 0:00:00.507861 till is : 1 day, 17:15:57.299998  DT : minsamplelf  5 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.002\n",
      "16 / 18432 duration for modelling : 0:00:00.811829 till is : 1 day, 17:15:58.111827  DT : minsamplelf  5 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.005\n",
      "17 / 18432 duration for modelling : 0:00:00.603818 till is : 1 day, 17:15:58.715645  DT : minsamplelf  5 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.05\n",
      "18 / 18432 duration for modelling : 0:00:00.475873 till is : 1 day, 17:15:59.191518  DT : minsamplelf  5 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.01\n",
      "19 / 18432 duration for modelling : 0:00:00.903770 till is : 1 day, 17:16:00.095288  DT : minsamplelf  5 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.001\n",
      "currnt:\n",
      "\n",
      "\n",
      " MODEL {'algo': 'DT', 'Maks Fiturs': 0.2, 'criteria': 'entropy', 'Min Sample leaf': 5, 'Maks depth': 16, 'Min sampleing split': 4, 'class weight': 'None', ' Min Impurity decrease ': 0.001}\n",
      " TP 798\n",
      " FP 262\n",
      " FN 1444\n",
      " TN 6541\n",
      " PRECISION 0.7521206409048068\n",
      " RECALL 0.3557735176103433\n",
      " F1 0.12694404270779033\n",
      " auc roc 0.8698545716895901\n",
      " auc pr 0.6412544761661523\n",
      " Balanced Error Rate 0.13014542831040987\n",
      " Features and contributions :\n",
      "Avg Probability of Y : 0.4541636677208443\n",
      "Avg Probability of N : 0.14147581886670738\n",
      "Min Probability of Y : 0.00869697894415624\n",
      "Top Probability of Y : 0.7693965517241379\n",
      " top model \n",
      "\n",
      "\n",
      " MODEL {'algo': 'DT', 'Maks Fiturs': 0.2, 'criteria': 'entropy', 'Min Sample leaf': 4, 'Maks depth': 16, 'Min sampleing split': 4, 'class weight': 'balanced', 'Min Impurity decrease ': 0.001}\n",
      " TP 1783\n",
      " FP 1456\n",
      " FN 459\n",
      " TN 5347\n",
      " PRECISION 0.5503086419753086\n",
      " RECALL 0.7949175211769951\n",
      " F1 0.18652784470615763\n",
      " auc roc 0.8657194974720578\n",
      " auc pr 0.6486755000247012\n",
      " Balanced Error Rate 0.1342805025279422\n",
      " Features and contributions :\n",
      "Avg Probability of Y : 0.6736988844221286\n",
      "Avg Probability of N : 0.27887423161372543\n",
      "Min Probability of Y : 0.006081557822851374\n",
      "Top Probability of Y : 0.9238944062473473\n",
      "20 / 18432 duration for modelling : 0:00:00.823792 till is : 1 day, 17:16:00.919080  DT : minsamplelf  5 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.02\n",
      "21 / 18432 duration for modelling : 0:00:00.535859 till is : 1 day, 17:16:01.454939  DT : minsamplelf  5 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.002\n",
      "22 / 18432 duration for modelling : 0:00:00.603851 till is : 1 day, 17:16:02.058790  DT : minsamplelf  5 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.005\n",
      "23 / 18432 duration for modelling : 0:00:00.547884 till is : 1 day, 17:16:02.606674  DT : minsamplelf  5 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.05\n",
      "24 / 18432 duration for modelling : 0:00:00.439865 till is : 1 day, 17:16:03.046539  DT : minsamplelf  6 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.01\n",
      "currnt:\n",
      "\n",
      "\n",
      " MODEL {'algo': 'DT', 'Maks Fiturs': 0.2, 'criteria': 'gini', 'Min Sample leaf': 6, 'Maks depth': 16, 'Min sampleing split': 4, 'class weight': 'None', ' Min Impurity decrease ': 0.01}\n",
      " TP 260\n",
      " FP 81\n",
      " FN 1982\n",
      " TN 6722\n",
      " PRECISION 0.7602339181286549\n",
      " RECALL 0.115916183682568\n",
      " F1 0.0469703433698859\n",
      " auc roc 0.7454435474300773\n",
      " auc pr 0.45139467763436975\n",
      " Balanced Error Rate 0.25455645256992265\n",
      " Features and contributions :\n",
      "Avg Probability of Y : 0.3682425830394794\n",
      "Avg Probability of N : 0.20792117736473542\n",
      "Min Probability of Y : 0.05986878075451066\n",
      "Top Probability of Y : 0.6995348837209302\n",
      " top model \n",
      "\n",
      "\n",
      " MODEL {'algo': 'DT', 'Maks Fiturs': 0.2, 'criteria': 'entropy', 'Min Sample leaf': 4, 'Maks depth': 16, 'Min sampleing split': 4, 'class weight': 'balanced', 'Min Impurity decrease ': 0.001}\n",
      " TP 1783\n",
      " FP 1456\n",
      " FN 459\n",
      " TN 5347\n",
      " PRECISION 0.5503086419753086\n",
      " RECALL 0.7949175211769951\n",
      " F1 0.18652784470615763\n",
      " auc roc 0.8657194974720578\n",
      " auc pr 0.6486755000247012\n",
      " Balanced Error Rate 0.1342805025279422\n",
      " Features and contributions :\n",
      "Avg Probability of Y : 0.6736988844221286\n",
      "Avg Probability of N : 0.27887423161372543\n",
      "Min Probability of Y : 0.006081557822851374\n",
      "Top Probability of Y : 0.9238944062473473\n",
      "25 / 18432 duration for modelling : 0:00:00.483871 till is : 1 day, 17:16:03.530410  DT : minsamplelf  6 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.001\n",
      "26 / 18432 duration for modelling : 0:00:00.511871 till is : 1 day, 17:16:04.042281  DT : minsamplelf  6 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.02\n",
      "27 / 18432 duration for modelling : 0:00:00.427918 till is : 1 day, 17:16:04.470199  DT : minsamplelf  6 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.002\n",
      "28 / 18432 duration for modelling : 0:00:00.507843 till is : 1 day, 17:16:04.978042  DT : minsamplelf  6 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.005\n",
      "29 / 18432 duration for modelling : 0:00:00.599849 till is : 1 day, 17:16:05.577891  DT : minsamplelf  6 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.05\n",
      "currnt:\n",
      "\n",
      "\n",
      " MODEL {'algo': 'DT', 'Maks Fiturs': 0.2, 'criteria': 'gini', 'Min Sample leaf': 6, 'Maks depth': 16, 'Min sampleing split': 4, 'class weight': 'None', ' Min Impurity decrease ': 0.05}\n",
      " TP 0\n",
      " FP 0\n",
      " FN 2242\n",
      " TN 6803\n",
      " PRECISION 0.0\n",
      " RECALL 0.0\n",
      " F1 0.0\n",
      " auc roc 0.5\n",
      " auc pr 0.2478717523493643\n",
      " Balanced Error Rate 0.5\n",
      " Features and contributions :\n",
      "Avg Probability of Y : 0.20213799805635888\n",
      "Avg Probability of N : 0.2021379980563554\n",
      "Min Probability of Y : 0.2021379980563654\n",
      "Top Probability of Y : 0.2021379980563654\n",
      " top model \n",
      "\n",
      "\n",
      " MODEL {'algo': 'DT', 'Maks Fiturs': 0.2, 'criteria': 'entropy', 'Min Sample leaf': 4, 'Maks depth': 16, 'Min sampleing split': 4, 'class weight': 'balanced', 'Min Impurity decrease ': 0.001}\n",
      " TP 1783\n",
      " FP 1456\n",
      " FN 459\n",
      " TN 5347\n",
      " PRECISION 0.5503086419753086\n",
      " RECALL 0.7949175211769951\n",
      " F1 0.18652784470615763\n",
      " auc roc 0.8657194974720578\n",
      " auc pr 0.6486755000247012\n",
      " Balanced Error Rate 0.1342805025279422\n",
      " Features and contributions :\n",
      "Avg Probability of Y : 0.6736988844221286\n",
      "Avg Probability of N : 0.27887423161372543\n",
      "Min Probability of Y : 0.006081557822851374\n",
      "Top Probability of Y : 0.9238944062473473\n",
      "30 / 18432 duration for modelling : 0:00:00.499876 till is : 1 day, 17:16:06.077767  DT : minsamplelf  6 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.01\n",
      "31 / 18432 duration for modelling : 0:00:00.607873 till is : 1 day, 17:16:06.685640  DT : minsamplelf  6 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.001\n",
      "32 / 18432 duration for modelling : 0:00:00.947725 till is : 1 day, 17:16:07.633365  DT : minsamplelf  6 maksFitursslction : 0.2 maksDpth : 16 minsamplesplit : 4min Impurity dcrs0.02\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-65789cf8ca58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;31m#assignment.rf(part_id)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0massignment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpart_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;31m#assignment.gboost(part_id)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-39-02b6b588f142>\u001b[0m in \u001b[0;36mdtc\u001b[1;34m(self, part_id)\u001b[0m\n\u001b[0;32m    369\u001b[0m                   \u001b[0mind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 371\u001b[1;33m                   \u001b[0mauc_pr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_perf_n\u001b[0m  \u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodelling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'DT'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_perf_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_perf_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_props1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    372\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m                   \u001b[0mmodel_perf_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_perf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-39-02b6b588f142>\u001b[0m in \u001b[0;36mmodelling\u001b[1;34m(self, model, targt, targt2, prdictors, train, test, model_typ, model_perf_list, model_perf_, model_props, ind, o_, idnt)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[0mmodel_predictions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m     \u001b[0mmodel_proba\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'predictions'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    852\u001b[0m             \u001b[0mnormalizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    853\u001b[0m             \u001b[0mnormalizer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnormalizer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 854\u001b[1;33m             \u001b[0mproba\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "  assignment=Assignment(\"C:/Users/lenovo/Documents/Assignment 1/config.json\")\n",
    "  assignment.input_head()\n",
    "\n",
    "  #assignment.input_distribution()\n",
    "\n",
    "  #assignment.input_data[0:10]\n",
    "\n",
    "  assignment.feature_engineering()\n",
    "  assignment.feature_distribution()\n",
    "  \n",
    "  #assignment.feature_pruning()\n",
    "   \n",
    "  \n",
    "  pcsv_full=assignment.input_data\n",
    "   \n",
    "  pcsv_full[pcsv_full==np.inf]=np.nan\n",
    "  pcsv_full.fillna(0,inplace=True)\n",
    "  \n",
    "  target='approved'\n",
    "\n",
    "  target2='alt_flag'\n",
    "\n",
    "  pcsv_full[target2]=[0 if a==0 else 1 for a in pcsv_full[target]]\n",
    "\n",
    "  predictors=[a for a in pcsv_full if a not in [target,target2]]\n",
    "\n",
    "  # Converting string/categorical variables to indices\n",
    "    \n",
    "  pcsv2=pd.DataFrame({col: pcsv_full[col].astype('category').cat.codes for col in pcsv_full}, index=pcsv_full.index)\n",
    "   \n",
    "  #80-20% Split of Train and Test Data\n",
    "\n",
    "  positives=pcsv2[pcsv2[target]==1]\n",
    "\n",
    "  negatives=pcsv2[pcsv2[target]==0]\n",
    "\n",
    "  positives1=positives[round(len(positives)/5):]\n",
    "  positives2=positives[:round(len(positives)/5)]\n",
    "  Positives_80=positives1\n",
    "  Positives_20=positives2\n",
    "\n",
    "  train=pd.concat([Positives_80,negatives[round(len(negatives)/5):]])\n",
    "  test= pd.concat([Positives_20,negatives[:round(len(negatives)/5)]])\n",
    "\n",
    "  trtst=pcsv2\n",
    "  print(\" TRAIN DATA TARGET DISTRIBUTION \")\n",
    "  print(train[target].value_counts())\n",
    "\n",
    "  tr2=train\n",
    "  tst2= test\n",
    "  print(\" TEST DATA TARGET DISTRIBUTION \")\n",
    "  print( test[target2].value_counts() )\n",
    "  train[target]=tr2[target]\n",
    "  test[target]=tst2[target]\n",
    "\n",
    "  #train=pcsv2\n",
    "  #test=train\n",
    "  ui_=0\n",
    "  pr=[]\n",
    "  # Dividing workload for every processor cores using multi-core programming\n",
    "  for part_id in range(psutil.cpu_count()-2):\n",
    "\n",
    "    if ui_==0:\n",
    "        #pass\n",
    "        #assignment.rf(part_id)\n",
    "        \n",
    "        assignment.dtc(part_id)\n",
    "        \n",
    "        #assignment.gboost(part_id)\n",
    "        \n",
    "    if ui_!=0:\n",
    "\n",
    "      arg =[part_id]\n",
    "\n",
    "      p= Process( target=assignment.dtc , args =(arg) )\n",
    "\n",
    "      p.start()\n",
    "\n",
    "      pr.append(p)\n",
    "\n",
    "        \n",
    "        \n",
    "  if ui_!=0:\n",
    "\n",
    "   # stalling for all cores processes to complete\n",
    "\n",
    "   for wg in pr:\n",
    "     wg.join()\n",
    "\n",
    "  algo='rf'\n",
    "  rst_lst=[]\n",
    "   \n",
    "  print(' dt ')\n",
    "  \n",
    "  # TO PROCURE PREDICTED PROBABILITY\n",
    "  #dtr = DTC( max_depth=16,min_samples_split=6,criterion='entropy', max_features=0.5, min_samples_leaf=4 , min_impurity_decrease=0.001)\n",
    "  #auc_pr,model_perf  =modelling(dtr,target,target2,predictors,train,train,'DT',pr,model_perf,{},ind=1,o_=1)\n",
    "   \n",
    "  \"\"\"  GRID SEARCH on Other Techniques such as RF and GBoost Takes more time from PC.. needs GPUs \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" BEST MODEL SO FAR FROM GRID SEARCH Decision Tree IS \n",
    "\n",
    "\n",
    "     MODEL\t\n",
    "     {'algo': 'DT', 'Maks Fiturs': 0.5, 'criteria': 'gini', 'Min Sample leaf': 5, 'Maks depth': 6,\n",
    "     'Min sampling split': 16, 'class weight': 'None', ' Min Impurity decrease ': 0.002}\n",
    "     \n",
    "     TP\t       : 1575\n",
    "     FP\t       :345\t \n",
    "     TN\t       :6458\t \n",
    "     FN\t       :667\t \n",
    "     PRECISION : 0.819885476\t \n",
    "     RECALL    : 0.702184574\t \n",
    "     F1\t       : 0.228269208\t \n",
    "     AUC_ROC   : 0.844584164\t\n",
    "     BER (balanced Error Rate) : 0.155415836\t \n",
    "     AUC_PR\t   : 0.746829475\t\n",
    "     AVG Probability of Y\t0.581622991\t \n",
    "     AVG Probability of N\t0.03553647\n",
    "     Min Probability of Y: 0\n",
    "     Max Probability of Y: 1\n",
    "\n",
    "\n",
    "BEST MODEL FROM GBM GRID SEARCH IS:\n",
    "     \n",
    "     MODEL {'algo': 'GBM', 'loss': 'deviance', 'Subsampling': 0.1, 'NumTrs': 500, 'Maks Fiturs': 0.2, \n",
    "     'Learning rate': 0.01, 'Maks depth': 16, 'Min sampling split': 16}\n",
    " \n",
    "     TP 1219\n",
    "     FP 351\n",
    "     FN 1023\n",
    "     TN 6452\n",
    "     PRECISION 0.7759388924252069\n",
    "     RECALL 0.543468568880963\n",
    "     F1 0.1818129873428656\n",
    "     auc roc 0.9053952820048562\n",
    "     auc pr 0.7686359862739767\n",
    "     Balanced Error Rate 0.0946047179951438\n",
    "     Features and contributions :\n",
    "     [('gender', 0.0029153905578678005), ('date_of_birth', 0.047829859206671994), ('workclass', 0.030329925958473215),\n",
    "     ('education_level', 0.019853006561685118), ('education_num', 0.07527902231522515), \n",
    "     ('marital_status', 0.013478993158479344), ('occupation', 0.04370178221814543),\n",
    "     ('relationship', 0.09103391973722465), ('capital_gain', 0.09553318766971383),\n",
    "     ('capital_loss', 0.026982921494765805), ('hours_per_week', 0.06418012921459622), \n",
    "     ('address', 0.10478250232306009), ('email', 0.10669845453478409), \n",
    "     ('inquiry_purpose_code', 0.03558648819881797), ('institute_type', 0.013275798504502032),\n",
    "     ('account_type', 0.021349947358194114), ('asset_class_cd', 0.007336848507644418), \n",
    "     ('asset_code', 0.006365574874894791), ('portfolio_type', 0.004794805620225104),\n",
    "     ('age', 0.06459150864450301), ('state', 0.06716462612907452), ('mail_accnt', 0.045280960981271344), \n",
    "     ('house_type', 0.011654346230179923)]\n",
    "     \n",
    "     Avg Probability of Y : 0.5250741707918904\n",
    "     Avg Probability of N : 0.10669522865578085\n",
    "     Min Probability of Y : 0.009516564771497529\n",
    "     Top Probability of Y : 0.9768237363604723\n",
    "\n",
    "\n",
    "    IT has the Highest AUC_PR which is the metric for classs imbalanced dataset\n",
    "\n",
    "\n",
    "\n",
    "This model shows answers a question of whether to approve or not approve a credit card application \n",
    "for an applicant\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.how much to approve for an applicant depends upon his credit history and credit score \n",
    "    which is based on:\n",
    "        \n",
    "        a. how consistent he has payed off his loans/bills (35%)\n",
    "        b. current loan/bills he has to pay  (30%)\n",
    "        c. new credit (10%)\n",
    "        d. type of credit (10%)\n",
    "        f, For how long he has been consistently paying off his bills/loans (15%)  \n",
    "        g. unused credits adds to the score\n",
    "        \n",
    "        From Salary:\n",
    "        We can decide upon the amount of credit to an applicant based on their salary statements:\n",
    "        with an EMI Ranging upto 65% of Salary and loan amount not more than a years salary or \n",
    "        $8000 whichever is lower\n",
    "        \n",
    "        From CIBIL Score or Credit Score:\n",
    "        Credit Score (CIBIL Score) Ranges and cap Amount we can approve for an applicant:\n",
    "                800-850         upto $8000\n",
    "                740-799         upto $7000\n",
    "                670-739         upto $6000\n",
    "                580-669         upto $5000\n",
    "        \n",
    "        From Collateral/assets:\n",
    "          For a new guy whose scores are not known, upto 70% of amount on the valuation of \n",
    "          collateral/assets can be approved on the credit card. \n",
    "          But this is an 1 hr evaluation of credit so this may not be viable option\n",
    "        \n",
    "        From Amount of Tax He is paying to Govt or he is yet to pay should be considered  \n",
    "        \n",
    "        From his partner/Parents/Guardian/Gauranteer Salary or CIBIL Score or Collateral \n",
    "        or Tax paid\n",
    "        \n",
    "        \n",
    "        Or a Weighted combination of above using a Polynomial Regression can be obtained \n",
    "        to provide an amount to to approve for an applicant \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
